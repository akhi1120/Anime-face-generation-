# Anime Face Generation using GANs 

This project implements a Generative Adversarial Network (GAN) to generate anime-style faces. 
We use the Anime Face Dataset from Kaggle and train a DCGAN-inspired architecture (Deep Convolutional GAN). 
The model learns patterns of anime faces and produces new, realistic-looking images. 

## 1. Instructions for Running the Code 
cd Anime_Face_Generation_using_GANs

## 3. Install Dependencies 
Make sure you have Python, then install required libraries: 
pip install torch torchvision matplotlib numpy 
Optional (for metrics): 
pip install torchmetrics torch-fidelity 

## 4. Download Dataset 
- Dataset: [Anime Face Dataset on Kaggle](https://www.kaggle.com/splcher/animefacedataset) 
- Extract the dataset into a folder like: 
Anime_Face_Generation_using_GANs/dataset/faces/ 
Your dataset path should look like: 
dataset/ 
└── faces/ 
├── 1.png 
├── 2.png 
├── ... 

## 4. Run Training 
python gan_anime_faces.py 
During training: 
- Model will generate sample outputs and save them in `outputs/samples/`. 
- Loss curves will be saved in `outputs/loss_curves.png`. 
GAN Architecture 
### Generator 
- Input: random noise vector (`latent_dim = 100`). 
- Several ConvTranspose2D + BatchNorm + ReLU layers. 
- Output: `64x64 RGB` image with Tanh activation (range `[-1,1]`). 
### Discriminator 
- Input: `64x64 RGB` image. 
- Several Conv2D + BatchNorm + LeakyReLU layers. 
- Final output: single probability (`real` vs `fake`) with Sigmoid. 
## Training Process 
1. Data Preprocessing 
- Resize images to `64x64`. 
- Normalize pixel values to `[-1,1]`. 
- Apply light augmentation (random horizontal flip). 
2. Discriminator Training 
- Train on real images (label = 0.9, label smoothing). 
- Train on fake images generated by Generator (label = 0). 
3. Generator Training
- Generate fake images. 
- Try to fool the Discriminator (label = 1). 
4. Optimization 
- Optimizer: Adam (`lr=0.0002, betas=(0.5, 0.999)`). 
- Loss: Binary Cross Entropy (BCE). 
5. Outputs 
- Save generated samples after each epoch in `outputs/samples/`. 
- Plot generator vs discriminator losses (`outputs/loss_curves.png`). 
## Evaluation Results and Analysis 
### Metrics 
We evaluated the model with: 
- Inception Score (IS): measures quality and diversity. 
- Frechet Inception Distance (FID): compares distribution of real vs fake images. 
Example (from small-scale training): 
 Inception Score: 2.80 ± 0.23
 FID Score: 0.70
### Observations 
- Model successfully learns to generate anime-like faces after a few epochs. 
- Generator improves steadily while Discriminator alternates between learning real vs fake signals. 
- Loss curves show typical GAN dynamics: not strictly decreasing, but oscillating. 
## Future Improvements 
- Add stronger data augmentation (color jitter, random crop). 
- Try Wasserstein GAN with Gradient Penalty (WGAN-GP). 
- Train longer on GPU for higher quality results. 

